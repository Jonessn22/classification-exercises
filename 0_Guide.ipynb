{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72815d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import splitting and imputing functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# import local files\n",
    "import env\n",
    "import acquire\n",
    "\n",
    "import os\n",
    "\n",
    "# turn off pink boxes\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a99108b",
   "metadata": {},
   "source": [
    "# <span style=\"color: #c48f7f\"> I. Data Acquisition </style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7605a564",
   "metadata": {},
   "source": [
    "## Step 1: Connect to Codeup Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7c1d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to connect to Codeup Database\n",
    "\n",
    "def get_connection(db, user = env.user, host = env.host, password = env.password):\n",
    "    '''\n",
    "    This function uses my info from the env file to create a connection url that \n",
    "    returns the user credentials needed to access the requested Codeup database.\n",
    "    It takes in a string name of a database an an argument.\n",
    "    '''\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{db}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5f56e2",
   "metadata": {},
   "source": [
    "## Step 2b: Read data from Codeup Database into DataFrame\n",
    "<i>(feeds into function in 2a)</i>\n",
    "\n",
    "- df_name = pd.read_sql('sql_query', get_connection('db_name')) ------> SQL QUERY\n",
    "- df_name = pd.read_csv('link/file_name/file_path/csv_export_url') ------------------>\n",
    "    - Google Sheet \n",
    "        - sheet_url = 'link'\n",
    "        - csv_export_url = sheet_url.replace('/edit#gid=', '/export?format=csv&gid=')\n",
    "- df_name = pd.read_excel('excel_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60283ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_database_name_data():\n",
    "    '''\n",
    "    This function reads in the [database_name] data from the Codeup Database into a\n",
    "    Pandas DataFrame.\n",
    "    '''\n",
    "#     sequel query\n",
    "    sql_query = 'Select * from table_name'\n",
    "    \n",
    "#     read in DataFrame from Codeup DB\n",
    "    df_name = pd.read_sql(sql_query, get_connection('database_name'))\n",
    "    \n",
    "    return df_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33edcaac",
   "metadata": {},
   "source": [
    "## Step 2a: Cache Data\n",
    "Writing DataFrame to .csv file using df_name.to_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20635f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_database_name_data():\n",
    "    '''\n",
    "    This function reads in the [database_name] data from the Codeup Database, writes\n",
    "    data to a .csv file if a local file does not already exist, and returns a df.\n",
    "    '''\n",
    "    if os.path.isfile('df_name.csv'):\n",
    "#         If .csv exists, read in data from .csv file\n",
    "        df_name = pd.read_csv('df_name.csv', index_col = 0)\n",
    "    \n",
    "    else:\n",
    "#         Read fresh data from Database into a DataFrame (referencing function from above cell)\n",
    "        df_name = new_database_name_data()\n",
    "        \n",
    "#         ... and write DataFrame to .csv file\n",
    "        df_name.to_csv('df_name.csv')\n",
    "    \n",
    "    return df_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6709319f",
   "metadata": {},
   "source": [
    "# <span style=\"color: #c48f7f\">II. Data Preparation </style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01baf7b9",
   "metadata": {},
   "source": [
    "## Step 1: Summarize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef7ce48",
   "metadata": {},
   "source": [
    "Acquire and General Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24abc837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire the data using acquire.py file function\n",
    "#     df_name = acquire.get_database_name_data()\n",
    "\n",
    "# sample of the DataFrame\n",
    "#     df_name.head()\n",
    "\n",
    "# numbers of rows and columns\n",
    "#     df_name.shape\n",
    "\n",
    "# information about the DataFrame:\n",
    "#     -- column names\n",
    "#     -- datatypes\n",
    "#     -- missing values\n",
    "#     df_name.info()\n",
    "\n",
    "# summary statistics for numeric columns\n",
    "#     df_name.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd6775b",
   "metadata": {},
   "source": [
    "For loop to visualize numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f9e2ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop to visualize the distributions for the numeric columns\n",
    "#     df_name_num_cols = df_name.columns[[df_name[col].dtype == 'int64' for col in df_name.columns]]\n",
    "\n",
    "#     for col in df_name_num_cols:\n",
    "#         plt.hist(df[col])\n",
    "#         plt.title(col)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80789f8",
   "metadata": {},
   "source": [
    "For loop to get breakdowns for object columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d94f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop to get the breakdowns of the object columns\n",
    "#     df_name_obj_cols = df_name.columns[[df_name[col].dtype == 'O' for col in df_name.columns]]\n",
    "\n",
    "#     for col in obj_cols:\n",
    "#         print(df_name[col].value_counts())\n",
    "#         print(df[col].value_counts(normalize = True, dropna = False))\n",
    "#         print('-----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df641f5",
   "metadata": {},
   "source": [
    "To bin columns with continuous numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60bc6034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to bin continuous numeric values\n",
    "#     df_name.column_name.value_counts(bins = x, sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da2d6c",
   "metadata": {},
   "source": [
    "To find missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9981449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find missing values\n",
    "#     missing = df_name.isnull().sum()\n",
    "#     missing[missing > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199d5f4f",
   "metadata": {},
   "source": [
    "## Step 2: Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea5f9a0",
   "metadata": {},
   "source": [
    "Drop duplicates and fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc4ebff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "#     df_name = df_name.drop_duplicates\n",
    "\n",
    "# Verify shape of data\n",
    "#     df_name.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef30b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with too many missing values\n",
    "#     df_name_cols_to_drop = ['col_1', 'col_2' ...]\n",
    "#     df_name = df_name.drop(columns = df_name_cols_to_drop)\n",
    "\n",
    "# Verify shape of data\n",
    "#     df_name.shape\n",
    "\n",
    "# Preview DataFrame and verify columns were dropped\n",
    "#     df_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19bdab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing values with most common value\n",
    "#     df_name['column_name'] = df_name.column_name.fillna(value = 'fill_value')\n",
    "\n",
    "# Validate that missing values have been filled (this line of code should return 0)\n",
    "#     df_name.column_name.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9561097",
   "metadata": {},
   "source": [
    "Create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c53c2051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy DataFrame\n",
    "#     df_name_dummies = pd.get_dummies(df_name[['col_1', 'col_2' ...]], dummy_na = False,\n",
    "#                                                                         drop_first = [True])\n",
    "#     df_name_dummies.head()\n",
    "\n",
    "# Concatenate the dummy DataFrame with original DataFrame\n",
    "#     df_name = pd.concat([df_name, df_name_dummies], axis = 1)\n",
    "#     df_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de50ca03",
   "metadata": {},
   "source": [
    "### <span style=\"background-color: #c48f7f\"><span style=\"color: #ffffff\">|  Clean Data Function  |</span></span>\n",
    "- drops duplicates\n",
    "- fills missing values\n",
    "- creates dummy vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e6a8d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_data(df):\n",
    "#     '''\n",
    "#     This function cleans the data and does the following:\n",
    "#         - drops duplicate observations\n",
    "#         - drops columns with too many missing values ['col_1', 'col_2', ...]\n",
    "#         - fill missing values with most common, 'common_value'\n",
    "#         - creates dummy variables from col_1, col_2, ...\n",
    "#     '''\n",
    "#     df = df.drop_duplicates()\n",
    "#     df = df.drop(columns = ['col_drop_1', 'col_drop_2' ...])\n",
    "    \n",
    "#     df['fill_col'] = df.fill_col.fillna(value = 'fill_value')\n",
    "    \n",
    "#     dummy_df = pd.get_dummies(df[['dum_col_1', 'dum_col_2' ...]], drop_first = True)\n",
    "#     df = pd.concat([df, dummy_df], axis = 1)\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee14474",
   "metadata": {},
   "source": [
    "## Step 3: Split Data\n",
    "#### | Train | *** | Validate | *** | Test |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a96b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20% test, 80% train_validate\n",
    "#     of the 80% train_validate: 30% validate, 70% train\n",
    "#     .24% validate, .56 train\n",
    "\n",
    "train, test = train_test_split(df, test_size = .2, \n",
    "                               random_state = 123,\n",
    "                              stratify = df.target)\n",
    "train, validate = train_test_split()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
