{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad49bcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import splitting and imputing functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# import local files\n",
    "import env\n",
    "import acquire\n",
    "\n",
    "import os\n",
    "\n",
    "# turn off pink boxes\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf54b7f",
   "metadata": {},
   "source": [
    "# <span style=\"color: #c48f7f\"> I. Data Acquisition </style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d65a3",
   "metadata": {},
   "source": [
    "## Step 1: Connect to Codeup Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1936f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to connect to Codeup Database\n",
    "\n",
    "def get_connection(db, user = env.user, host = env.host, password = env.password):\n",
    "    '''\n",
    "    This function uses my info from the env file to create a connection url that \n",
    "    returns the user credentials needed to access the requested Codeup database.\n",
    "    It takes in a string name of a database an an argument.\n",
    "    '''\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{db}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5bc456",
   "metadata": {},
   "source": [
    "## Step 2b: Read data from Codeup Database into DataFrame\n",
    "<i>(feeds into function in 2a)</i>\n",
    "\n",
    "- df_name = pd.read_sql('sql_query', get_connection('db_name')) ------> SQL QUERY\n",
    "- df_name = pd.read_csv('link/file_name/file_path/csv_export_url') ------------------>\n",
    "    - Google Sheet \n",
    "        - sheet_url = 'link'\n",
    "        - csv_export_url = sheet_url.replace('/edit#gid=', '/export?format=csv&gid=')\n",
    "- df_name = pd.read_excel('excel_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05846230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_database_name_data():\n",
    "    '''\n",
    "    This function reads in the [database_name] data from the Codeup Database into a\n",
    "    Pandas DataFrame.\n",
    "    '''\n",
    "#     sequel query\n",
    "    sql_query = 'Select * from table_name'\n",
    "    \n",
    "#     read in DataFrame from Codeup DB\n",
    "    df_name = pd.read_sql(sql_query, get_connection('database_name'))\n",
    "    \n",
    "    return df_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec11c8ab",
   "metadata": {},
   "source": [
    "## Step 2a: Cache Data\n",
    "Writing DataFrame to .csv file using df_name.to_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d19d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_database_name_data():\n",
    "    '''\n",
    "    This function reads in the [database_name] data from the Codeup Database, writes\n",
    "    data to a .csv file if a local file does not already exist, and returns a df.\n",
    "    '''\n",
    "    if os.path.isfile('df_name.csv'):\n",
    "#         If .csv exists, read in data from .csv file\n",
    "        df_name = pd.read_csv('df_name.csv', index_col = 0)\n",
    "    \n",
    "    else:\n",
    "#         Read fresh data from Database into a DataFrame (referencing function from above cell)\n",
    "        df_name = new_database_name_data()\n",
    "        \n",
    "#         ... and write DataFrame to .csv file\n",
    "        df_name.to_csv('df_name.csv')\n",
    "    \n",
    "    return df_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a16f3",
   "metadata": {},
   "source": [
    "# <span style=\"color: #c48f7f\">II. Data Preparation </style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5cff0e",
   "metadata": {},
   "source": [
    "## Step 1: Summarize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73363b71",
   "metadata": {},
   "source": [
    "Acquire and General Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "701db65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire the data using acquire.py file function\n",
    "#     df_name = acquire.get_database_name_data()\n",
    "\n",
    "# sample of the DataFrame\n",
    "#     df_name.head()\n",
    "\n",
    "# numbers of rows and columns\n",
    "#     df_name.shape\n",
    "\n",
    "# information about the DataFrame:\n",
    "#     -- column names\n",
    "#     -- datatypes\n",
    "#     -- missing values\n",
    "#     df_name.info()\n",
    "\n",
    "# summary statistics for numeric columns\n",
    "#     df_name.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd64e566",
   "metadata": {},
   "source": [
    "For loop to visualize numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc970a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop to visualize the distributions for the numeric columns\n",
    "#     df_name_num_cols = df_name.columns[[df_name[col].dtype == 'int64' for col in df_name.columns]]\n",
    "\n",
    "#     for col in df_name_num_cols:\n",
    "#         plt.hist(df[col])\n",
    "#         plt.title(col)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583292b9",
   "metadata": {},
   "source": [
    "For loop to get breakdowns for object columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aef68ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop to get the breakdowns of the object columns\n",
    "#     df_name_obj_cols = df_name.columns[[df_name[col].dtype == 'O' for col in df_name.columns]]\n",
    "\n",
    "#     for col in obj_cols:\n",
    "#         print(df_name[col].value_counts())\n",
    "#         print(df[col].value_counts(normalize = True, dropna = False))\n",
    "#         print('-----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce35c0fb",
   "metadata": {},
   "source": [
    "To bin columns with continuous numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bbd6c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to bin continuous numeric values\n",
    "#     df_name.column_name.value_counts(bins = x, sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf81d8d",
   "metadata": {},
   "source": [
    "To find missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76408e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find missing values\n",
    "#     missing = df_name.isnull().sum()\n",
    "#     missing[missing > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5061546e",
   "metadata": {},
   "source": [
    "## Step 2: Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83260827",
   "metadata": {},
   "source": [
    "Drop duplicates and fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13b083e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "#     df_name = df_name.drop_duplicates\n",
    "\n",
    "# Verify shape of data\n",
    "#     df_name.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "385576f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with too many missing values\n",
    "#     df_name_cols_to_drop = ['col_1', 'col_2' ...]\n",
    "#     df_name = df_name.drop(columns = df_name_cols_to_drop)\n",
    "\n",
    "# Verify shape of data\n",
    "#     df_name.shape\n",
    "\n",
    "# Preview DataFrame and verify columns were dropped\n",
    "#     df_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98992044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing values with most common value\n",
    "#     df_name['column_name'] = df_name.column_name.fillna(value = 'fill_value')\n",
    "\n",
    "# Validate that missing values have been filled (this line of code should return 0)\n",
    "#     df_name.column_name.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aebc45",
   "metadata": {},
   "source": [
    "Create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da5f9edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy DataFrame\n",
    "#     df_name_dummies = pd.get_dummies(df_name[['col_1', 'col_2' ...]], dummy_na = False,\n",
    "#                                                                         drop_first = [True])\n",
    "#     df_name_dummies.head()\n",
    "\n",
    "# Concatenate the dummy DataFrame with original DataFrame\n",
    "#     df_name = pd.concat([df_name, df_name_dummies], axis = 1)\n",
    "#     df_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65caaaf",
   "metadata": {},
   "source": [
    "### <span style=\"background-color: #c48f7f\"><span style=\"color: #ffffff\">|  Clean Data Function  |</span></span>\n",
    "- drops duplicates\n",
    "- fills missing values\n",
    "- creates dummy vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcee4e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_data(df):\n",
    "#     '''\n",
    "#     This function cleans the data and does the following:\n",
    "#         - drops duplicate observations\n",
    "#         - drops columns with too many missing values ['col_1', 'col_2', ...]\n",
    "#         - fill missing values with most common, 'common_value'\n",
    "#         - creates dummy variables from col_1, col_2, ...\n",
    "#     '''\n",
    "#     df = df.drop_duplicates()\n",
    "#     df = df.drop(columns = ['col_drop_1', 'col_drop_2' ...])\n",
    "    \n",
    "#     df['fill_col'] = df.fill_col.fillna(value = 'fill_value')\n",
    "    \n",
    "#     dummy_df = pd.get_dummies(df[['dum_col_1', 'dum_col_2' ...]], drop_first = True)\n",
    "#     df = pd.concat([df, dummy_df], axis = 1)\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b3ea43",
   "metadata": {},
   "source": [
    "## Step 3: Split Data\n",
    "#### | Train | *** | Validate | *** | Test |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc016fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20% test, 80% train_validate\n",
    "#     of the 80% train_validate: 30% validate, 70% train\n",
    "#     .24% validate, .56 train\n",
    "\n",
    "# train, test = train_test_split(df, test_size = .2, \n",
    "#                                random_state = 123,\n",
    "#                               stratify = df.target)\n",
    "\n",
    "# train, validate = train_test_split(train, test_size = .3,\n",
    "#                                    random_state = 123,\n",
    "#                                    stratify = train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161cb169",
   "metadata": {},
   "source": [
    "Validate the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0730c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'train ------> {train.shape}')\n",
    "# print(f'validate ------> {validate.shape}')\n",
    "# print(f'test ------> {test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbb2abd",
   "metadata": {},
   "source": [
    "### <span style=\"background-color: #c48f7f\"><span style=\"color: #ffffff\">|  Split Data Function  |</span></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4044d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    '''\n",
    "    This function takes in a DataFrame and returns train, validate, and test DataFrames;\n",
    "    and stratifies on the target variable\n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size = .2,\n",
    "                                           random_state = 123,\n",
    "                                           stratify = df.target)\n",
    "    \n",
    "    train, validate = train_test_split(train_validate, test_size = .3,\n",
    "                                      random_state = 123,\n",
    "                                      stratify = train_validate.target)\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4f2a44",
   "metadata": {},
   "source": [
    "Test out the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08cf5bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validate, test = split_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a387037f",
   "metadata": {},
   "source": [
    "Validate my split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "747e9813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'train -------> {train.shape}')\n",
    "# print(f'validate ----> {validate.shape}')\n",
    "# print(f'test --------> {test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e537ad9",
   "metadata": {},
   "source": [
    "## Step 4: Imputing Missing Values\n",
    "1. Create the imputer object, selecting the strategy used to impute\n",
    "    - Mean\n",
    "    - Median\n",
    "    - Mode (strategy = 'most_frequent')<br><br>\n",
    "2. Fit to train \n",
    "    - Compute the mean, median, or most_frequent (mode) for each of the columns that will be imputed.\n",
    "    - Store that value in the imputer object<br><br>\n",
    "2. Transform train: fill missing values in the train dataset with that value identified.<br><br>\n",
    "2. Transform validate and test: fill missing values with that value identified].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8b4a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only look at the train dataset after data split\n",
    "#     train.info()\n",
    "\n",
    "# 1. Create the SimpleImputer object (imputer instructions)---> will be stored in a variable called imputer\n",
    "#     imputer = SimpleImputer(missing_values = None, strategy = 'most_frequent')\n",
    "\n",
    "# 2. Fit the imputer columns in the training df so the imputer determines the value depending on the strategy \n",
    "# called\n",
    "#     imputer = imputer.fit(train[['col_name']])\n",
    "\n",
    "\n",
    "# 3. Next we will call transform on all three of our split data sets\n",
    "#     train[['col_name']] = imputer.transform(train[['col_name']])\n",
    "\n",
    "# 4. And finally calling transform on our validate and test data sets\n",
    "#     validate[['col_name']] = imputer.transform(validate[['col_name']])\n",
    "#     test[['col_name']] = imputer.transform(test[['col_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1fa40e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate there are no longer any null values in imputer column(s)\n",
    "#     train.col_name.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1384c4b5",
   "metadata": {},
   "source": [
    "### <span style=\"background-color: #c48f7f\"><span style=\"color: #ffffff\">|  Imputer Function  |</span></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09707b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_mode(train, test, validate):\n",
    "    '''\n",
    "    This function takes in the train, test, and validate DataFrames and imputes the mode for the selected\n",
    "    column to impute, returning imputed train, test, and validated DataFrames\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b48e330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
